{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbzbREBjgkPiv2BGAa0w+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anower120/AI-900-AIFundamentals/blob/main/RL_loan_approval_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The code sets up a RL loan approval system using Gym toolkit for developing and comparing RL algorithms.\n",
        "# This environment simulates the process of approving or denying loan applications based on borrower data.\n",
        "\n",
        "#Import the libraries\n",
        "# Importing Required Libraries\n",
        "import enum\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler\n",
        "import random\n",
        "\n",
        "# Constants\n",
        "DEFAULT_LOAN_TERMS = 36  # Loan term in months\n",
        "DEFAULT_INTEREST_RATE = 0.05  # Interest rate\n",
        "\n",
        "# Defining Actions for the RL Environment\n",
        "class Actions(enum.Enum):\n",
        "    Approve = 0\n",
        "    Deny = 1\n",
        "\n",
        "# Loan State Class\n",
        "class LoanState:\n",
        "    def __init__(self, interest_rate, loan_terms):\n",
        "        self.interest_rate = interest_rate\n",
        "        self.loan_terms = loan_terms\n",
        "\n",
        "    def reset(self, borrower_info):\n",
        "        self.borrower_info = np.array(borrower_info)\n",
        "        self.loan_approved = False\n",
        "        return self.encode()  # Return the encoded state\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.borrower_info.shape\n",
        "\n",
        "    def encode(self):\n",
        "        return self.borrower_info\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == Actions.Approve:\n",
        "            self.loan_approved = True\n",
        "            return self.calculate_reward(), True\n",
        "        self.loan_approved = False\n",
        "        return 0, True\n",
        "\n",
        "    def calculate_reward(self):\n",
        "        credit_score, income, loan_amount, employment_years = self.borrower_info\n",
        "        risk_factor = loan_amount / income\n",
        "        return 1.0 if credit_score > 700 and risk_factor < 0.5 and employment_years > 5 else -1.0\n",
        "\n",
        "# Loan Environment Class\n",
        "class LoanEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, borrower_data):\n",
        "        self.borrower_data = borrower_data\n",
        "        self._state = LoanState(DEFAULT_INTEREST_RATE, DEFAULT_LOAN_TERMS)\n",
        "        self.action_space = gym.spaces.Discrete(n=len(Actions))\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(4,), dtype=np.float32)\n",
        "        self.seed()\n",
        "\n",
        "    def reset(self):\n",
        "        borrower_info = self.np_random.choice(self.borrower_data)\n",
        "        return self._state.reset(borrower_info)  # Return the encoded state from LoanState\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        action = Actions(action_idx)\n",
        "        reward, done = self._state.step(action)\n",
        "        next_state = self._state.encode()  # Encode the current state as the next state\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        # Rendering logic (if applicable)\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        # Close environment\n",
        "        pass\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed1 = seeding.np_random(seed)\n",
        "        seed2 = seeding.hash_seed(seed1 + 1) % 2 ** 31\n",
        "        return [seed1, seed2]\n",
        "\n",
        "# Sample Borrower Data (Normalization Required)\n",
        "borrower_data = [\n",
        "    (750, 60000, 10000, 10),\n",
        "    (650, 40000, 5000, 5),\n",
        "    (500, 30000, 15000, 2)\n",
        "]\n",
        "\n",
        "# Normalize the Data\n",
        "scaler = MinMaxScaler()\n",
        "borrower_data_normalized = scaler.fit_transform(borrower_data)\n",
        "\n",
        "# Q-Learning Model Setup\n",
        "\n",
        "# Discretize the State Space\n",
        "n_bins = 5\n",
        "est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
        "est.fit(borrower_data_normalized)\n",
        "\n",
        "# Convert Multi-dimensional State into a Single Integer Index\n",
        "def discretize_state(state):\n",
        "    # Reshape the state array to 2D (1, -1) for a single sample\n",
        "    discretized = est.transform(state.reshape(1, -1))[0]\n",
        "    # Convert the multi-dimensional state into a single integer index\n",
        "    return sum([discretized[i] * (n_bins ** i) for i in range(len(discretized))]).astype(int)\n",
        "\n",
        "\n",
        "# Initialize Q-table\n",
        "state_size = n_bins ** len(borrower_data_normalized[0])\n",
        "action_size = len(Actions)\n",
        "q_table = np.zeros((state_size, action_size))\n",
        "\n",
        "# Action Selection Function\n",
        "def choose_action(state_index):\n",
        "    return env.action_space.sample() if random.uniform(0, 1) < epsilon else np.argmax(q_table[state_index])\n",
        "\n",
        "# Q-table Update Function\n",
        "def update_q_table(state_index, action, reward, next_state_index):\n",
        "    old_value = q_table[state_index, action]\n",
        "    next_max = np.max(q_table[next_state_index])\n",
        "    q_table[state_index, action] = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "\n",
        "# Training the Model\n",
        "alpha, gamma, epsilon, epsilon_decay = 0.1, 0.6, 0.1, 0.99\n",
        "num_episodes = 1000\n",
        "env = LoanEnv(borrower_data_normalized)\n",
        "\n",
        "for i in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    state_index = discretize_state(state)\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = choose_action(state_index)\n",
        "        next_state, reward, done = env.step(action)\n",
        "        next_state_index = discretize_state(next_state)\n",
        "        update_q_table(state_index, action, reward, next_state_index)\n",
        "        state_index = next_state_index\n",
        "        total_reward += reward\n",
        "        epsilon = max(epsilon * epsilon_decay, 0.01)  # Decay epsilon\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Episode: {i}, Total Reward: {total_reward}, Epsilon: {epsilon:.4f}\")\n",
        "\n",
        "# Model Evaluation\n",
        "num_test_episodes = 100\n",
        "total_rewards, correct_approvals, correct_denials = 0, 0, 0\n",
        "\n",
        "for i in range(num_test_episodes):\n",
        "    state = env.reset()  # Get the initial state from the environment\n",
        "    state_index = discretize_state(state)  # Discretize the state\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state_index])\n",
        "        next_state, reward, done = env.step(action)\n",
        "        next_state_index = discretize_state(next_state)\n",
        "        episode_reward += reward\n",
        "        if action == Actions.Approve.value and reward > 0:\n",
        "            correct_approvals += 1\n",
        "        elif action == Actions.Deny.value and reward >= 0:\n",
        "            correct_denials += 1\n",
        "        state_index = next_state_index\n",
        "\n",
        "    total_rewards += episode_reward\n",
        "\n",
        "# Output Results\n",
        "average_reward = total_rewards / num_test_episodes\n",
        "print(f\"Average Reward: {average_reward}\")\n",
        "print(f\"Correct Approvals: {correct_approvals}\")\n",
        "print(f\"Correct Denials: {correct_denials}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woy7FXbMNhYL",
        "outputId": "08a74296-e9dc-4553-9000-72db9ccb339b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/seeding.py:159: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/seeding.py:203: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
            "  deprecation(\n",
            "<ipython-input-20-6a1be798e4fb>:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  risk_factor = loan_amount / income\n",
            "<ipython-input-20-6a1be798e4fb>:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  risk_factor = loan_amount / income\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Total Reward: -1.0, Epsilon: 0.0990\n",
            "Episode: 100, Total Reward: 0, Epsilon: 0.0362\n",
            "Episode: 200, Total Reward: 0, Epsilon: 0.0133\n",
            "Episode: 300, Total Reward: 0, Epsilon: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-6a1be798e4fb>:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  risk_factor = loan_amount / income\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 400, Total Reward: 0, Epsilon: 0.0100\n",
            "Episode: 500, Total Reward: 0, Epsilon: 0.0100\n",
            "Episode: 600, Total Reward: 0, Epsilon: 0.0100\n",
            "Episode: 700, Total Reward: 0, Epsilon: 0.0100\n",
            "Episode: 800, Total Reward: 0, Epsilon: 0.0100\n",
            "Episode: 900, Total Reward: 0, Epsilon: 0.0100\n",
            "Average Reward: 0.0\n",
            "Correct Approvals: 0\n",
            "Correct Denials: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieOzhp0zjZWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}