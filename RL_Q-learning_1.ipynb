{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOWjSjPCRBS9V1NpPrj6Tw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anower120/AI-900-AIFundamentals/blob/main/RL_Q-learning_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The code sets up a RL loan approval system using Gym toolkit for developing and comparing RL algorithms.\n",
        "# This environment simulates the process of approving or denying loan applications based on borrower data.\n",
        "\n",
        "#Import the libraries\n",
        "import enum  # enumeration used to work with a number of constants\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "\n",
        "# Constants for the environment\n",
        "DEFAULT_LOAN_TERMS = 36  # Example loan term in months\n",
        "DEFAULT_INTEREST_RATE = 0.05  # Example interest rate\n",
        "\n",
        "class Actions(enum.Enum):\n",
        "    Approve = 0\n",
        "    Deny = 1\n",
        "\n",
        "class LoanState:\n",
        "    def __init__(self, interest_rate, loan_terms):\n",
        "        self.interest_rate = interest_rate\n",
        "        self.loan_terms = loan_terms\n",
        "\n",
        "    def reset(self, borrower_info):\n",
        "        self.borrower_info = np.array(borrower_info)\n",
        "        self.loan_approved = False\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.borrower_info.shape\n",
        "\n",
        "    def encode(self):\n",
        "        return self.borrower_info\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == Actions.Approve:\n",
        "            self.loan_approved = True\n",
        "            reward = self.calculate_reward()\n",
        "        else:\n",
        "            self.loan_approved = False\n",
        "            reward = 0\n",
        "        done = True\n",
        "        return reward, done\n",
        "\n",
        "    def calculate_reward(self):\n",
        "        # Improved reward function considering multiple factors\n",
        "        credit_score, income, loan_amount, employment_years = self.borrower_info\n",
        "        risk_factor = loan_amount / income\n",
        "        if credit_score > 700 and risk_factor < 0.5 and employment_years > 5:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return -1.0\n",
        "\n",
        "class LoanEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, borrower_data):\n",
        "        self.borrower_data = borrower_data\n",
        "        self._state = LoanState(DEFAULT_INTEREST_RATE, DEFAULT_LOAN_TERMS)\n",
        "        self.action_space = gym.spaces.Discrete(n=len(Actions))\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(4,), dtype=np.float32)\n",
        "        self.seed()\n",
        "\n",
        "    def reset(self):\n",
        "        borrower_info = self.np_random.choice(self.borrower_data)\n",
        "        self._state.reset(borrower_info)\n",
        "        return self._state.encode()\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        action = Actions(action_idx)\n",
        "        reward, done = self._state.step(action)\n",
        "        obs = self._state.encode()\n",
        "        info = {\"loan_approved\": self._state.loan_approved}\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed1 = seeding.np_random(seed)\n",
        "        seed2 = seeding.hash_seed(seed1 + 1) % 2 ** 31\n",
        "        return [seed1, seed2]\n",
        "\n",
        "# Sample Borrower Data\n",
        "borrower_data = [\n",
        "    (750, 60000, 10000, 10),\n",
        "    (650, 40000, 5000, 5),\n",
        "    (500, 30000, 15000, 2)\n",
        "]\n",
        "\n",
        "#  Improved Q-Learning Model with State Discretization\n",
        "import random\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "# Learning parameters\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "epsilon_decay = 0.99\n",
        "\n",
        "# Discretize the state space\n",
        "n_bins = 5\n",
        "est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
        "est.fit(borrower_data)  # Assuming borrower_data is a numpy array\n",
        "\n",
        "def discretize_state(state):\n",
        "    discretized = est.transform([state])[0]\n",
        "    # Convert the multi-dimensional state into a single integer index\n",
        "    return sum([discretized[i] * (n_bins ** i) for i in range(len(discretized))]).astype(int)\n",
        "\n",
        "\n",
        "def choose_action(state_index):\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        return np.argmax(q_table[state_index])\n",
        "\n",
        "\n",
        "def update_q_table(state_index, action, reward, next_state_index):\n",
        "    old_value = q_table[state_index, action]\n",
        "    next_max = np.max(q_table[next_state_index])\n",
        "    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "    q_table[state_index, action] = new_value\n",
        "\n",
        "\n",
        "# Train the model\n",
        "num_episodes = 1000\n",
        "env = LoanEnv(borrower_data)\n",
        "\n",
        "for i in range(num_episodes):\n",
        "    state = discretize_state(env.reset())\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = choose_action(state)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        next_state = discretize_state(next_state)\n",
        "\n",
        "        update_q_table(state, action, reward, next_state)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            epsilon = max(epsilon * epsilon_decay, 0.01)  # Decay epsilon\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Episode: {i}, Total Reward: {total_reward}\")\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the performance of the Q-learning model\n",
        "# Evaluation parameters\n",
        "# Evaluation parameters\n",
        "num_test_episodes = 100\n",
        "total_rewards = 0\n",
        "correct_approvals = 0\n",
        "correct_denials = 0\n",
        "\n",
        "for i in range(num_test_episodes):\n",
        "    state = discretize_state(env.reset())\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])  # Choose action based on Q-table\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        next_state = discretize_state(next_state)\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        if action == Actions.Approve.value and reward > 0:\n",
        "            correct_approvals += 1\n",
        "        elif action == Actions.Deny.value and reward >= 0:\n",
        "            correct_denials += 1\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    total_rewards += episode_reward\n",
        "\n",
        "# Calculate average reward\n",
        "average_reward = total_rewards / num_test_episodes\n",
        "\n",
        "print(f\"Average Reward: {average_reward}\")\n",
        "print(f\"Correct Approvals: {correct_approvals}\")\n",
        "print(f\"Correct Denials: {correct_denials}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woy7FXbMNhYL",
        "outputId": "5bbac7cb-d2c2-4281-80bf-d679dcdb1ac0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/seeding.py:159: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/seeding.py:203: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Total Reward: -1.0\n",
            "Episode: 100, Total Reward: 0\n",
            "Episode: 200, Total Reward: 0\n",
            "Episode: 300, Total Reward: 0\n",
            "Episode: 400, Total Reward: 1.0\n",
            "Episode: 500, Total Reward: 0\n",
            "Episode: 600, Total Reward: 0\n",
            "Episode: 700, Total Reward: 1.0\n",
            "Episode: 800, Total Reward: 1.0\n",
            "Episode: 900, Total Reward: 1.0\n",
            "Average Reward: 0.33\n",
            "Correct Approvals: 33\n",
            "Correct Denials: 67\n"
          ]
        }
      ]
    }
  ]
}